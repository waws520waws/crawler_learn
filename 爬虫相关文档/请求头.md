### 【问题1】若请求头中有 `Connection: keep-alive` 参数
- 此参数的作用：
    - 持久连接
    - 参考：https://segmentfault.com/q/1010000019503002
- 【解决方法】要通过 `requests.session()` 去发起请求
  - 使用
      ```python
        import requests 
        #实例化session
        session = requests.session()
        # 使用session发起请求来获取登录后的cookie,cookie已经存在session中
        response = session.get(url, headers=req_header)
      ```
  - session 会话的作用：
    - 在一定时间内多次请求同一个网站，不用每次都登陆（会默认使用该session之前使用的cookie等参数）
  
### 【问题2】怎么自动获取 cookie
- 【解决方法1】requests 中的 session()，如上
- 【解决方式2】通过 selenium 获取
- 【解决方式3】通过js逆向找到加密参数，构造出cookie

### 3、cookie字符串转字典
```python
import requests
cookie_str = ""
li = cookie_str.split('; ')
cookie_dic = {}
for i in li:
    k, v = i.split('=', 1)
    cookie_dic[k] = v
```

### 4、scrapy中如何设置 cookie
- 【注意】scrapy中设置cookie时必须是 字典格式
- 方法1：
    - middlewares中设置cookie
        - 在middlewares中的 downloadermiddleware 中的 process_request 中配置cookie，配置如下：
            request.cookies={
              '':'',
              '':'',
            }
    
- 方法2：
    - 在spider爬虫主文件中，重写start_request方法，在scrapy的Request函数的参数中传递cookies
```python
import scrapy
# 重载start_requests方法
def start_requests(self):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0"
    }
    # 指定cookies
    cookies = {
        'uuid': '66a0f5e7546b4e068497.1542881406.1.0.0',
        '_lxsdk_cuid': '1673ae5bfd3c8-0ab24c91d32ccc8-143d7240-144000-1673ae5bfd4c8',
        '__mta': '222746148.1542881402495.1542881402495.1542881402495.1',
        'ci': '20',
        'rvct': '20%2C92%2C282%2C281%2C1',
        '_lx_utm': 'utm_source%3DBaidu%26utm_medium%3Dorganic',
        '_lxsdk_s': '1674f401e2a-d02-c7d-438%7C%7C35'
    }

            # 再次请求到详情页，并且声明回调函数callback，dont_filter=True 不进行域名过滤，meta给回调函数传递数据
    yield scrapy.Request(detailUrl, headers=headers, cookies=cookies, callback=self.parse, meta={'myItem': item},  dont_filter=True)
```

### 5、请求头中有 _token 参数
- `_token` 参数一般出现在 PHP 框架 laravel 框架中，出现它表示你需要获取到一个 cookie 中的参数才可以继续爬取，参数名为 laravel_session
- Token是服务端生成的一串字符串，以作客户端进行请求的一个令牌，当第一次登录后，服务器生成一个Token便将此Token返回给客户端，
  以后客户端只需带上这个Token前来请求数据即可，无需再次带上用户名和密码。

### 6、IP代理池
- 概念：将网上的ip保存到本地文件或者数据库中，需要用的时候从中取出
- 访问免费代理的网站 —> 正则/xpath提取 ip和端口 —> 测试ip是否可用 —> 可用则保存 —> 使用ip爬虫 —> 检查过期，抛弃ip
- 定期的去检测这些 ip 可不可以用，那么下次你要使用代理 ip 的时候，你只需要去自己的 ip 代理池里面拿就行了
- 开源 ip代理池 `ProxyPool`
    - 【参考】https://blog.csdn.net/weixin_44517301/article/details/103393145
    - ProxyPool下载地址：https://github.com/Python3WebSpider/ProxyPool.git
    - 会抓取某页面上的有效的ip
- 测试代理是否成功可以访问这个网站：http://icanhazip.com，这个网站会返回当前请求的ip地址，来测试代理ip是否配置成功
```python
import requests
url = 'http://icanhazip.com'
proxy = {
    "http":"35.224.248.29:3128",
}
response = requests.get(url,proxies=proxy)
print(response.text)
```
- 构建ip代理池的方法：https://steven-cloud.blog.csdn.net/article/details/102538757
  - 构建代理池接口的作用：运行flask后，我们每次需要代理IP时，只需要请求flask中设置的路径，就可得到一个IP（而️不需求每次都连接数据库，再取出）