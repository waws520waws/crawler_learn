## 一、url去重
- url去重应该只需要同一网站（同一域名）下的url去重，否则那么多网站，那么多url都存入redis中，占太多内存
### 1、使用redis中的集合进行url去重
- 案例：small_spider/scrapy1/scrapy的基本使用.md 中的 增量式爬虫
### 2、可以使用BloomFilter进行url去重
- 案例：100例 例78
-


## 二、内容去重
### 1、使用 BloomFilter（布隆过滤器） 进行内容去重（也可以是url去重）
- 简介：Bloom Filter是由Bloom在1970年提出的一种多 哈希函数 映射的快速查找算法，
      通常应用在一些需要 快速判断某个元素是否属于集合，但是并不严格要求100%正确的场合。
- 优点：
    - 不需要存储key，节省空间（使用哈希函数）
    - 相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势
    - 方便并行实现
    - 布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势
- 缺点
    - 有一定的误识别率（算法判断key在集合中时，有一定的概率key其实不在集合中）
        - 因此BloomFilter不适合那些“零错误”的应用场合
    - 不能从布隆过滤器中删除元素
- 使用场景
    - 1）黑名单应用（邮件黑名单）
    - 2）网络爬虫去重（和我们要学的增量爬虫产生了关联）
    - 3）K-V系统（键值对）快速判断Key是否存在
    - 4）减少缓存穿透
        - 某些存储系统的设计中，会存在空查询缺陷：当查询一个不存在的key时，需要访问慢设备，导致效率低下。
          比如一个前端页面的缓存系统，可能这样设计：先查询某个页面在本地是否存在，如果存在就直接返回，如果不存在，就从后端获取，
          但是当频繁从缓存系统查询一个页面时，缓存系统将会频繁请求后端，把压力导入后端。
          这时只要增加一个bloom算法的服务，后端插入一个key时，也在这个服务中设置一次，
          需要查询后端时，先判断key在后端是否存在，这样就能避免后端的压力。
- 安装 （依赖包可在 github上查阅）
    - 【参考】https://dream.blog.csdn.net/article/details/108225659
    - 安装依赖包 bitarray
    - 安装 pybloom_live：`pip install pybloom_live`
- 使用
    - 100例 例78
    
### 2、根据加密得到的字符串是否存在redis中：
- 选择特定的字段（能够唯一标识数据的字段），使用加密算法（MD5，sha1）将字段进行加密，生成字符串，存入Redis的集合中；  
  后续新来一条数据，同样的方式进行加密；如果得到的字符串在Redis中存在，说明数据存在，对数据进行更新，否则说明数据不存在，对数据进行插入。
- 同时，使用MD5加密可以减少占用redis内存
  
### 3、根据内容相似度去重
- jieba库
- simhash算法